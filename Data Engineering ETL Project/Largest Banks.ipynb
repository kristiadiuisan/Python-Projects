{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff9a3c9-6d80-4522-9038-1854dbf36a9b",
   "metadata": {},
   "source": [
    "# Acquiring and Processing Information on the World's Largest Banks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba2d5d-4f0d-4485-b069-b3f89abf0423",
   "metadata": {},
   "source": [
    "# Project Scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8642f6-2afe-41a2-9cab-6955a8902241",
   "metadata": {},
   "source": [
    "You have been hired as a data engineer by research organization. Your boss has asked you to create a code that can be used to compile the list of the top 10 largest banks in the world ranked by market capitalization in billion USD. Further, the data needs to be transformed and stored in GBP, EUR and INR as well, in accordance with the exchange rate information that has been made available to you as a CSV file. The processed information table is to be saved locally in a CSV format and as a database table.\n",
    "\n",
    "Your job is to create an automated system to generate this information so that the same can be executed in every financial quarter to prepare the report.\n",
    "\n",
    "Particulars of the code to be made have been shared below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3d10a-bc3e-408f-9862-36dfc9a5cf01",
   "metadata": {},
   "source": [
    "Code name: banks_project.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4155e45-61d3-4717-804f-a5eda8ddb520",
   "metadata": {},
   "source": [
    "Data URL"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f499018-ec0e-4726-a6ae-7172b032299e",
   "metadata": {},
   "source": [
    "https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c39595-5827-4c7a-b8c8-45a5b03d00a0",
   "metadata": {},
   "source": [
    "Exchange rate CSV path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb3536b4-5aa0-485f-b00d-4d3a6a923a80",
   "metadata": {},
   "source": [
    "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057aa2c-dabc-4260-9f8c-7ca5cc4e5e04",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e30ebd-0599-49a5-8373-4820ac07e06c",
   "metadata": {},
   "source": [
    "Before you start building the code, you need to install the required libraries for it.\n",
    "\n",
    "The libraries needed for the code are as follows:\n",
    "\n",
    "1. requests - The library used for accessing the information from the URL.\n",
    "\n",
    "2. bs4 - The library containing the BeautifulSoup function used for webscraping.\n",
    "\n",
    "3. pandas - The library used for processing the extracted data, storing it to required formats and communicating with the databases.\n",
    "\n",
    "4. sqlite3 - The library required to create a database server connection.\n",
    "\n",
    "5. numpy - The library required for the mathematical rounding operation as required in the objectives.\n",
    "\n",
    "6. datetime - The library containing the function datetime used for extracting the timestamp for logging purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa529a4-3a56-45cc-96e2-6003c2239df3",
   "metadata": {},
   "source": [
    "While requests, sqlite3, and datetime come bundled with python, the other libraries will have to be installed."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0061d964-4679-4dfb-aed9-f5391422cba5",
   "metadata": {},
   "source": [
    "python3.11 -m pip install pandas\n",
    "python3.11 -m pip install numpy\n",
    "python3.11 -m pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "941074c0-e857-4ff4-8c51-04f7e8a74a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\krist\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\krist\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: bs4 in c:\\users\\krist\\anaconda3\\lib\\site-packages (0.0.2)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\krist\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\krist\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\krist\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\krist\\anaconda3\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\krist\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\krist\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=5fad042e430f18918ad0d16d7cc6565480a77edb31dc4f0bd358e55af33c10df\n",
      "  Stored in directory: c:\\users\\krist\\appdata\\local\\pip\\cache\\wheels\\01\\46\\3b\\e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas bs4 wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aaa4d9-8df7-4ef8-b2c0-b61e4fed2fa6",
   "metadata": {},
   "source": [
    "Download the required exchange rate file using the terminal command:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61aa9a88-bb22-40cf-bfa5-51ee76be16cb",
   "metadata": {},
   "source": [
    "wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d22c28-410b-48bc-97f1-7337ba0ae1dd",
   "metadata": {},
   "source": [
    "# Code structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc89731-b64a-43f8-950e-b7848de0ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime \n",
    "\n",
    "# Suppress generated warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae47a7-3efb-4fb3-9d7b-89ca6911d0e7",
   "metadata": {},
   "source": [
    "## Task 1: Logging function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458d82a6-6fe9-4ce7-b821-be7404a861b9",
   "metadata": {},
   "source": [
    "Write the function to log the progress of the code, log_progress(). The function accepts the message to be logged and enters it to a text file code_log.txt.\n",
    "\n",
    "The format to be used for logging must have the syntax:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70c63dc5-22ca-4c08-9862-2f64da69fc92",
   "metadata": {},
   "source": [
    "<time_stamp> : <message>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52783a-a12d-497e-a0e2-c2dab6e14af5",
   "metadata": {},
   "source": [
    "Logging needs to be done using the log_progress() funciton. This function will be called multiple times throughout the execution of this code and will be asked to add a log entry in a .txt file, etl_project_log.txt. The entry is supposed to be in the following format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859cd37c-eba3-40d0-af20-8590b140bc62",
   "metadata": {},
   "source": [
    "Here, message text is passed to the function as an argument. Each entry must be in a separate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f98a721-9b56-47e7-8fe6-e0ad4fc42a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message at a given stage of the \n",
    "    code execution to a log file. Function returns nothing.'''\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(\"./code_log.txt\",\"a\") as f: \n",
    "        f.write(timestamp + ' : ' + message + '\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752ff57-cfd0-49bc-b92b-30be6ce956c7",
   "metadata": {},
   "source": [
    "## Task 2 : Extraction of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2e457-1b5c-4c0a-93bc-df6c1cd7d066",
   "metadata": {},
   "source": [
    "Download the required exchange rate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1120d12-c059-480e-827c-6595fa7f0eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exchange_rate (1).csv'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the CSV data first into a local `exchange_rate.csv` file\n",
    "import wget\n",
    "wget.download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d78ec-f4d2-45c5-806a-f5f2aec3c52f",
   "metadata": {},
   "source": [
    "Analyze the webpage on the given URL:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e80c5fed-60a9-4d4e-bd49-f7ddb7449550",
   "metadata": {},
   "source": [
    "https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a49c91-912f-4a29-ac70-ae5a47140d18",
   "metadata": {},
   "source": [
    "Identify the position of the required table under the heading By market capitalization. Write the function extract() to retrieve the information of the table to a Pandas data frame.\n",
    "\n",
    "Note: Remember to remove the last character from the Market Cap column contents, like, '\\n', and typecast the value to float format.\n",
    "\n",
    "Write a function call for extract() and print the returning data frame.\n",
    "\n",
    "Make the relevant log entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6d9134d-8410-4d3e-8b5a-35f3ec7a53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    ''' The purpose of this function is to extract the required\n",
    "    information from the website and save it to a dataframe. The\n",
    "    function returns the dataframe for further processing. '''\n",
    "\n",
    "    # Extract the web page as text\n",
    "    page = requests.get(url).text\n",
    "\n",
    "    # Parse the text into an HTML object\n",
    "    data = BeautifulSoup(page,'html.parser')\n",
    "\n",
    "    # Create an empty pandas DataFrame named df with columns as the table_attribs.\n",
    "    df = pd.DataFrame(columns=table_attribs)\n",
    "\n",
    "    # Extract all 'tbody' attributes of the HTML object and then extract all the rows of the index 2 table using the 'tr' attribute.\n",
    "    tables = data.find_all('tbody')\n",
    "    rows = tables[0].find_all('tr')\n",
    "\n",
    "    # Check the contents of each row, having attribute ‘td’\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')\n",
    "        if len(col)!=0:\n",
    "            data_dict = {\"Name\": col[1].find_all(\"a\")[1][\"title\"],\n",
    "                         \"MC_USD_Billion\": float(col[2].contents[0][:-1])}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "\n",
    "            # Append all these dictionaries one by one to the dataframe.\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05883255-c8ac-489d-8b61-ad08f0c128bf",
   "metadata": {},
   "source": [
    "## Task 3 : Transformation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5e01f-4905-4339-8147-add64f094bf9",
   "metadata": {},
   "source": [
    "The Transform function needs to perform the following tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c701f-9cd0-449c-bfc7-cdf2c6464886",
   "metadata": {},
   "source": [
    "1. Read the exchange rate CSV file and convert the contents to a dictionary so that the contents of the first columns are the keys to the dictionary and the contents of the second column are the corresponding values."
   ]
  },
  {
   "cell_type": "raw",
   "id": "68815b02-1333-4f58-af19-58ce74657778",
   "metadata": {},
   "source": [
    "dict = dataframe.set_index('Col_1_header').to_dict()['Col_2_header']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4686822a-d90c-4b19-ba48-7a6287b461db",
   "metadata": {},
   "source": [
    "2. Add 3 different columns to the dataframe, viz. MC_GBP_Billion, MC_EUR_Billion and MC_INR_Billion, each containing the content of MC_USD_Billion scaled by the corresponding exchange rate factor. Remember to round the resulting data to 2 decimal places.\n",
    "\n",
    "A sample statement is being provided for adding the MC_GBP_Billion column. You can use this to add the other two statements on your own."
   ]
  },
  {
   "cell_type": "raw",
   "id": "71b522a4-6458-4cb7-bbb3-fdf85dca41e9",
   "metadata": {},
   "source": [
    "df['MC_GBP_Billion'] = [np.round(x*exchange_rate['GBP'],2) for x in df['MC_USD_Billion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18625036-fe17-46a5-a999-7b66805942c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    ''' This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies'''\n",
    "\n",
    "    # Read exchange rate CSV file\n",
    "    df_exchange_rate = pd.read_csv('./exchange_rate.csv')\n",
    "\n",
    "    # Convert to dict\n",
    "    exchange_rate = df_exchange_rate.set_index('Currency').to_dict()['Rate']\n",
    "\n",
    "    # Add MC_GBP_Billion, MC_EUR_Billion, and MC_INR_Billion\n",
    "    # columns to dataframe. Round off to two decimals\n",
    "    df[\"MC_GBP_Billion\"] = [np.round(x * exchange_rate[\"GBP\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "    df[\"MC_EUR_Billion\"] = [np.round(x * exchange_rate[\"EUR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "    df[\"MC_INR_Billion\"] = [np.round(x * exchange_rate[\"INR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df1248-fdbf-4d3f-ad2d-d6d335b3b44c",
   "metadata": {},
   "source": [
    "## Task 4: Loading to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24cc0b-cdb1-4721-9b70-a3aceae4bb3a",
   "metadata": {},
   "source": [
    "Write the function to load the transformed data frame to a CSV file, like load_to_csv(), in the path mentioned in the project scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "828fbcb3-4a91-4f25-836f-a4a2acc7a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, csv_path):\n",
    "    ''' This function saves the final dataframe as a `CSV` file \n",
    "    in the provided path. Function returns nothing.'''\n",
    "    df.to_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b572e-140d-4c48-9471-1730472a1ecc",
   "metadata": {},
   "source": [
    "## Task 5: Loading to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9e774-c0aa-43cb-b9c7-f15fd50e2992",
   "metadata": {},
   "source": [
    "Write the function to load the transformed data frame to an SQL database, like, load_to_db(). Use the database and table names as mentioned in the project scenario.\n",
    "\n",
    "Before calling this function, initiate the connection to the SQLite3 database server with the name Banks.db. Pass this connection object, along with the required table name Largest_banks and the transformed data frame, to the load_to_db() function in the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a102cc6-6e61-4a6b-956d-e4ae5cf0f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    ''' This function saves the final dataframe to as a database table\n",
    "    with the provided name. Function returns nothing.'''\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92294db-4186-41ac-89e5-262cb1bb136e",
   "metadata": {},
   "source": [
    "## Task 6: Function to Run queries on Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e59f7-7869-4762-9017-7e5d177b7bcb",
   "metadata": {},
   "source": [
    "Write the function run_queries() that accepts the query statement, and the SQLite3 Connection object, and generates the output of the query. The query statement should be printed along with the query output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01b625d3-449a-4fcf-93d9-0964f2734e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_statement, sql_connection):\n",
    "    ''' This function runs the stated query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc3a4e-2a49-4f8c-b263-8fc1b99c1e6c",
   "metadata": {},
   "source": [
    "## Define required entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6643c1bd-96c6-491d-83f1-980816b0f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path = './Largest_banks_data.csv'\n",
    "log_file = \"./code_log.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e3ec9-4499-40e5-9eab-c63c0c486913",
   "metadata": {},
   "source": [
    "## Function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2643e-bb25-4e15-89e0-081bb77de1ab",
   "metadata": {},
   "source": [
    "Declaring known values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bae83274-0c43-4430-9ccd-059678717bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_progress('Preliminaries complete. Initiating ETL process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d533f-cf00-43ad-9bd0-e42ab4c2e02b",
   "metadata": {},
   "source": [
    "Call extract() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54e703f6-e2fc-4ec1-9d6d-ccc4ffeb21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name  MC_USD_Billion\n",
      "0                           JPMorgan Chase          432.92\n",
      "1                          Bank of America          231.52\n",
      "2  Industrial and Commercial Bank of China          194.56\n",
      "3               Agricultural Bank of China          160.68\n",
      "4                                HDFC Bank          157.91\n",
      "5                              Wells Fargo          155.87\n",
      "6                                     HSBC          148.90\n",
      "7                           Morgan Stanley          140.83\n",
      "8                  China Construction Bank          139.82\n",
      "9                            Bank of China          136.81\n"
     ]
    }
   ],
   "source": [
    "df = extract(url, table_attribs)\n",
    "print(df)\n",
    "\n",
    "log_progress('Data extraction complete. Initiating Transformation process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee72fe-eaa8-4cfc-8889-470e0f6a376a",
   "metadata": {},
   "source": [
    "Call transform() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55e75fd4-934b-4386-bf0c-c5bf6dbde242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                                     HSBC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n"
     ]
    }
   ],
   "source": [
    "df = transform(df)\n",
    "print(df)\n",
    "\n",
    "log_progress('Data transformation complete. Initiating loading process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faabdead-bf34-423e-90a2-c4dc0e19d43e",
   "metadata": {},
   "source": [
    "Call load_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a6ecb24-2565-48d8-adbb-689c6670528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_csv(df, csv_path)\n",
    "\n",
    "log_progress('Data saved to CSV file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a1bba-0528-47fa-9975-c0cb3cd60efb",
   "metadata": {},
   "source": [
    "Initiate SQLite3 connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27a61201-fbc1-4e8b-abf4-ee5fa3bc44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_connection = sqlite3.connect(db_name)\n",
    "\n",
    "log_progress('SQL Connection initiated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb290b-1d45-44aa-822e-2aa741845ac9",
   "metadata": {},
   "source": [
    "Call load_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5eb971b2-e350-4cb4-b32e-8fb3d02b2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_db(df, sql_connection, table_name)\n",
    "\n",
    "log_progress('Data loaded to Database as a table, Executing queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bf2f8-a6a5-457b-9048-a7b98427706f",
   "metadata": {},
   "source": [
    "Call run_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef1548-ee51-42a2-8b34-6670fb331c13",
   "metadata": {},
   "source": [
    "1. Print the contents of the entire table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ea1a5ad-8e9e-40be-a78d-c63953f14c73",
   "metadata": {},
   "source": [
    "SELECT * FROM Largest_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "beca1aad-380d-4978-af8a-244793c0186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * from Largest_banks\n",
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                                     HSBC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n"
     ]
    }
   ],
   "source": [
    "query_statement = f\"SELECT * from {table_name}\"\n",
    "run_query(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0389a27-a0c6-4673-a5e3-5afc7e02038c",
   "metadata": {},
   "source": [
    "2. Print the average market capitalization of all the banks in Billion USD."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb683dba-856e-4f19-9a3c-09887ffd0c2f",
   "metadata": {},
   "source": [
    "SELECT AVG(MC_GBP_Billion) FROM Largest_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aec3772-145a-4c31-990e-da30c00c48d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
      "   AVG(MC_GBP_Billion)\n",
      "0              151.987\n"
     ]
    }
   ],
   "source": [
    "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
    "run_query(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aaf062-1a5e-4874-b811-28775aa59bfb",
   "metadata": {},
   "source": [
    "3. Print only the names of the top 5 banks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82641227-afa2-4bc5-a129-5097698ce8d5",
   "metadata": {},
   "source": [
    "SELECT Name from Largest_banks LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13a677b4-223b-418b-9922-ad5b80c08022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Name from Largest_banks LIMIT 5\n",
      "                                      Name\n",
      "0                           JPMorgan Chase\n",
      "1                          Bank of America\n",
      "2  Industrial and Commercial Bank of China\n",
      "3               Agricultural Bank of China\n",
      "4                                HDFC Bank\n"
     ]
    }
   ],
   "source": [
    "query_statement = f\"SELECT Name from {table_name} LIMIT 5\"\n",
    "run_query(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bff14c-3dc5-4d4f-9c32-890a110b132d",
   "metadata": {},
   "source": [
    "End process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d2b55bc-6648-42fa-a100-e351608000b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_progress('Process Complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ad70e-9536-42ed-94af-cde20f2f0cab",
   "metadata": {},
   "source": [
    "Close SQLite3 connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be4bf7f6-fc16-4e67-9cec-17adda923c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_connection.close()\n",
    "log_progress('Server Connection closed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807265b-b7cf-4391-9cf0-07e37ec26e8c",
   "metadata": {},
   "source": [
    "## Task 7: Verify log entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011b339-9a0c-4583-84ee-a10a345913aa",
   "metadata": {},
   "source": [
    "After updating all the log_progress() function calls, you have to run the code for a final execution. However, you will first have to remove the code_log.txt file, that would have been created and updated throughout the multiple executions of the code in this lab. You may remove the file using the following command on a terminal."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3b01a24-3c3d-465f-9a25-383e724df832",
   "metadata": {},
   "source": [
    "rm code_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e62f17e-cfd5-48bc-8eef-8d517907e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-May-16-13:12:36 : Preliminaries complete. Initiating ETL process\n",
      "2025-May-16-13:12:39 : Data extraction complete. Initiating Transformation process\n",
      "2025-May-16-13:12:39 : Data transformation complete. Initiating loading process\n",
      "2025-May-16-13:12:40 : Data saved to CSV file\n",
      "2025-May-16-13:12:40 : SQL Connection initiated.\n",
      "2025-May-16-13:12:40 : Data loaded to Database as a table, Executing queries\n",
      "2025-May-16-13:12:40 : Process Complete.\n",
      "2025-May-16-13:12:40 : Server Connection closed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(log_file, \"r\") as log:\n",
    "    LogContent = log.read()\n",
    "    print(LogContent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
